{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GENERAL IMPORTS\n",
    "\n",
    "import torch\n",
    "from mapping.datasets import RLDatasetFormatter\n",
    "from mapping.models import Discriminator, TransitionModel, LitAutoEncoder\n",
    "from mapping.config import LOGGING_DIR, TRAIN_WEIGHTS, ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING OF DATASETS\n",
    "\n",
    "dataset_t_path = 'data/UntrainedMCDataset500.csv'\n",
    "dataset_s_path = 'data/UntrainedPendDataset5000.csv'\n",
    "extended_dataset_t_path = 'data/UntrainedMCDataset5000.csv'\n",
    "test_dataset_s_path = 'data/UntrainedPendDataset500.csv'\n",
    "super_extended_dataset_t_path = 'data/UntrainedMCDataset50000.csv'\n",
    "\n",
    "\n",
    "data_formatter_t = RLDatasetFormatter().from_csv(dataset_t_path)\n",
    "data_formatter_s = RLDatasetFormatter().from_csv(dataset_s_path)\n",
    "test_data_formatter_s = RLDatasetFormatter().from_csv(test_dataset_s_path)\n",
    "ext_data_formatter_t = RLDatasetFormatter().from_csv(extended_dataset_t_path)\n",
    "super_ext_data_formatter_t = RLDatasetFormatter().from_csv(super_extended_dataset_t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | loss_criterion | L1Loss     | 0     \n",
      "1 | statefc        | Sequential | 8.5 K \n",
      "2 | actionfc       | Sequential | 8.4 K \n",
      "3 | predfc         | Sequential | 16.6 K\n",
      "----------------------------------------------\n",
      "33.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.5 K    Total params\n",
      "0.134     Total estimated model params size (MB)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py:262: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n",
      "  \"Could not log computational graph to TensorBoard: The `model.example_input_array` attribute\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1562: PossibleUserWarning: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 145.00it/s, loss=0.00196, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 139.27it/s, loss=0.00196, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "dataset_t = data_formatter_t.as_transitions()\n",
    "\n",
    "T = TransitionModel(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "T.train_model(dataset_t, model_dir='/T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1562: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 6/6 [00:00<00:00, 50.13it/s, loss=0.233, v_num=8] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 6/6 [00:00<00:00, 44.96it/s, loss=0.233, v_num=8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 99.00it/s, loss=2.08, v_num=7] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 96.39it/s, loss=2.08, v_num=7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1562: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 83.36it/s, loss=0.324, v_num=9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 75.69it/s, loss=0.324, v_num=9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 71.25it/s, loss=7.72, v_num=8] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 67.47it/s, loss=7.72, v_num=8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 79.82it/s, loss=0.0493, v_num=10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 73.15it/s, loss=0.0493, v_num=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 73.80it/s, loss=17.4, v_num=9] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 71.51it/s, loss=17.4, v_num=9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 53.69it/s, loss=0.012, v_num=11] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 46.89it/s, loss=0.012, v_num=11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 92.16it/s, loss=44.9, v_num=10] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 88.57it/s, loss=44.9, v_num=10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 72.77it/s, loss=0.00209, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 65.80it/s, loss=0.00209, v_num=12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 80.80it/s, loss=64.3, v_num=11] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 78.80it/s, loss=64.3, v_num=11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 59.90it/s, loss=8.46e-05, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 56.03it/s, loss=8.46e-05, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 85.43it/s, loss=71.3, v_num=12] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 81.56it/s, loss=71.3, v_num=12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 78.73it/s, loss=0.00806, v_num=14]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 72.08it/s, loss=0.00806, v_num=14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 837   \n",
      "1 | decoder | Sequential | 839   \n",
      "---------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 95.71it/s, loss=96.7, v_num=13] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 26/26 [00:00<00:00, 92.28it/s, loss=96.7, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type       | Params\n",
      "----------------------------------------------\n",
      "0 | sfc            | Sequential | 8.5 K \n",
      "1 | actionfc       | Sequential | 8.4 K \n",
      "2 | s1fc           | Sequential | 8.5 K \n",
      "3 | model          | Sequential | 24.7 K\n",
      "4 | loss_criterion | BCELoss    | 0     \n",
      "----------------------------------------------\n",
      "50.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "50.2 K    Total params\n",
      "0.201     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 38.45it/s, loss=0.000288, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 34.83it/s, loss=0.000288, v_num=15]\n"
     ]
    }
   ],
   "source": [
    "stringa = ''\n",
    "\n",
    "test_dataset_s = test_data_formatter_s.transition_identity()\n",
    "dataset_t = data_formatter_t.transition_identity()\n",
    "dataset_s = data_formatter_s.transition_identity()\n",
    "\n",
    "D = Discriminator(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "disc_dataset = data_formatter_t.transition_as_valid()\n",
    "D.train_model(disc_dataset, model_dir='/Discriminator', batch_size=100, epochs=20)\n",
    "\n",
    "source_triplet_size = data_formatter_s.state_size*2+data_formatter_s.action_size\n",
    "AE = LitAutoEncoder(T, D, dim_s=source_triplet_size, lambdas=TRAIN_WEIGHTS)\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "#while stringa != 'stop':\n",
    "\n",
    "#T = TransitionModel.load_from_checkpoint(T_model_checkpoint, s_dim=data_formatter_t.state_size, a_dim=data_formatter_t.action_size)\n",
    "#D = Discriminator.load_from_checkpoint(D_model_checkpoint, s_dim=data_formatter_t.state_size, a_dim=data_formatter_t.action_size)\n",
    "\n",
    "    AE._D = D.as_dict()['func']\n",
    "    AE.train_model(dataset_s, batch_size=200, model_dir=\"/AE\")\n",
    "\n",
    "    M =  AE.as_dict()['M']\n",
    "\n",
    "    test_dataset_s.shuffle()\n",
    "    #dataset_s.shuffle()\n",
    "    sas, _ = test_dataset_s[:len(dataset_t)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        synthetic_data = M(sas)\n",
    "\n",
    "    r_synth = torch.zeros((synthetic_data.shape[0],1))\n",
    "    s_synth,a_synth,s1_synth = torch.split(synthetic_data, [data_formatter_t.state_size, data_formatter_t.action_size, data_formatter_t.state_size],1)\n",
    "    data_formatter_synth = RLDatasetFormatter([s_synth, a_synth, r_synth, s1_synth])\n",
    "\n",
    "\n",
    "    #disc_dataset = data_formatter_t.transition_as_valid()\n",
    "    #fake_samples = data_formatter_synth.transition_as_fake()\n",
    "    #disc_dataset = disc_dataset.merge(fake_samples)\n",
    "    disc_dataset = data_formatter_synth.transition_as_fake()\n",
    "\n",
    "    #D = Discriminator(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "    D.train_model(disc_dataset, model_dir='/Discriminator', batch_size=100, epochs=20)\n",
    "\n",
    "    #stringa = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = lambda sas: AE.encoder(sas)\n",
    "\n",
    "dataset_s = data_formatter_s.transition_identity()\n",
    "\n",
    "sas, _ = dataset_s[:]\n",
    "\n",
    "with torch.no_grad():\n",
    "    synthetic_data = M(sas)\n",
    "r_synth = torch.zeros((synthetic_data.shape[0],1))\n",
    "s_synth,a_synth,s1_synth = torch.split(synthetic_data, [data_formatter_t.state_size, data_formatter_t.action_size, data_formatter_t.state_size],1)\n",
    "data_formatter_synth = RLDatasetFormatter([s_synth, a_synth, r_synth, s1_synth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_synth = data_formatter_synth.as_transitions()\n",
    "dataset_hybrid = data_formatter_t.as_transitions().merge(dataset_synth)\n",
    "T_hat = TransitionModel(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "T_hat.train_model(dataset_hybrid, model_dir='/T_hat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dataset_t = ext_data_formatter_t.as_transitions()\n",
    "\n",
    "sa, s1 = ext_dataset_t[:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T.eval()\n",
    "T_hat.eval()\n",
    "with torch.no_grad():\n",
    "    error = T(sa)-s1\n",
    "    plt.plot(sorted(torch.norm(error,dim=1,).detach().numpy(), reverse=True))\n",
    "    error = T_hat(sa)-s1\n",
    "    plt.plot(sorted(torch.norm(error,dim=1).detach().numpy(),reverse=True))\n",
    "\n",
    "plt.legend(['T', 'T_hat'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_dataset_t = ext_data_formatter_t.as_transitions()\n",
    "T_ext = TransitionModel(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "T_ext.train_model(ext_dataset_t, model_dir='/T_ext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_synth = data_formatter_synth.as_transitions()\n",
    "#T_synth = TransitionModel(data_formatter_t.state_size, data_formatter_t.action_size)\n",
    "#T_synth.train_model(dataset_synth, model_dir='/T_synth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_ext_dataset_t = super_ext_data_formatter_t.as_transitions()\n",
    "\n",
    "sa, s1 = super_ext_dataset_t[:]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [T,T_ext,T_hat#,T_synth\n",
    "]\n",
    "model_names = ['Trained on 500 target',\n",
    "               'Trained on 5000 target',\n",
    "               'Trained on 500 target + 5000 synthetic',\n",
    "               #'Trained on 5000 synthetic'\n",
    "               ]\n",
    "\n",
    "for m in models:\n",
    "    m = m.as_dict()['func']\n",
    "    with torch.no_grad():\n",
    "        error = torch.norm(m(sa) - s1, dim=1).detach().numpy()\n",
    "        plt.plot(sorted(error, reverse=True ))\n",
    "\n",
    "\n",
    "plt.legend(model_names)\n",
    "plt.title('Transition model trained using different datasets')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_state_distribution(dataset, name: str, bins: int = 100):\n",
    "    \"\"\"\n",
    "    Plot the distribution of states in a dataset.\n",
    "    \"\"\"\n",
    "    sa,s1 = dataset[:]\n",
    "    state_size = s1.shape[1]\n",
    "\n",
    "    # components = [s1[:,i].detach().numpy() for i in range(state_size)]\n",
    "\n",
    "    components = [[] for _ in range(state_size)]\n",
    "\n",
    "    for sa, s1 in dataset:\n",
    "        for i, c in enumerate(s1):\n",
    "            components[i].append(c.detach().numpy())\n",
    "\n",
    "    fig, axs = plt.subplots(state_size)\n",
    "\n",
    "    for i, c in enumerate(components):\n",
    "        axs[i].hist(c, bins=bins)\n",
    "        axs[i].set_ylabel(f\"Component {i}\")\n",
    "        axs[i].grid()\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"{name}\\nState Marginal Distributions\"\n",
    "    )  \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_state_distribution(data_formatter_t.as_transitions(), f\"MC Dataset ({len(dataset_t)} samples)\")\n",
    "plot_state_distribution(ext_dataset_t, f\"MC Dataset ({len(ext_dataset_t)} samples)\")\n",
    "plot_state_distribution(dataset_synth, f\"Mapped Dataset PEND2MC ({len(dataset_synth)} samples)\")\n",
    "plot_state_distribution(dataset_hybrid, f\"Hybrid Dataset MC500+Mapped5000 ({len(dataset_t) + len(dataset_synth)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
